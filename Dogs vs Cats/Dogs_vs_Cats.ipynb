{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dogs vs Cats",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvRscjYkYo4D",
        "colab_type": "text"
      },
      "source": [
        "###Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxXRd7aNhAsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "from shutil import copyfile\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXVUGKazZRXQ",
        "colab_type": "text"
      },
      "source": [
        "###Retrieve the required dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWdAdv73Z7ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Download the dataset\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "# Unzip the files and store them\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBp9Gc9BeAn8",
        "colab_type": "text"
      },
      "source": [
        "###Define the dataset directories for the ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQNAD8BsiZgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "try:\n",
        "    os.mkdir(\"/tmp/cats-v-dogs\")\n",
        "    os.makedirs(\"/tmp/cats-v-dogs/training/cats\")\n",
        "    os.makedirs(\"/tmp/cats-v-dogs/training/dogs\")\n",
        "    os.makedirs(\"/tmp/cats-v-dogs/testing/cats\")\n",
        "    os.makedirs(\"/tmp/cats-v-dogs/testing/dogs\")\n",
        "except OSError:\n",
        "    pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZoyfQTheYGT",
        "colab_type": "text"
      },
      "source": [
        "###Split the data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7YW3s3sSAk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Function to randomly split the data into training and test sets according to the specified split size\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    i = 0\n",
        "    for f in os.listdir(SOURCE):\n",
        "      if os.path.getsize(os.path.join(SOURCE, os.path.basename(f))) == 0:\n",
        "        os.remove(os.path.join(SOURCE, os.path.basename(f)))\n",
        "    L = len(os.listdir(SOURCE))\n",
        "    for f in random.sample(os.listdir(SOURCE), L):\n",
        "      if i < int(SPLIT_SIZE * L):\n",
        "        copyfile(os.path.join(SOURCE, os.path.basename(f)), os.path.join(TRAINING, os.path.basename(f)))\n",
        "      else:\n",
        "        copyfile(os.path.join(SOURCE, os.path.basename(f)), os.path.join(TESTING, os.path.basename(f)))\n",
        "      i = i + 1\n",
        "\n",
        "# Define the paths for the training and test sets\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "# Split the data\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Print the sizes of the training and test sets\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvvqsxchf5A5",
        "colab_type": "text"
      },
      "source": [
        "###Pre-process the data and perform image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asrqh_rit-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Pre-process and augment the training set\n",
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training\"\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'nearest')\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size = 50,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "# Pre-process the validation set\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size = 50,\n",
        "                                                              class_mode = 'binary',\n",
        "                                                              target_size=(150, 150))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXlF_T00fWUH",
        "colab_type": "text"
      },
      "source": [
        "###Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5rms_cuidP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define the layers for the model\n",
        "cd_model = tf.keras.models.Sequential ([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3), name = \"Conv1\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2,2), name = \"Pool1\"),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', name = \"Conv2\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2,2), name = \"Pool2\"),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', name = \"Conv3\"), \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2,2), name = \"Pool3\"),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', name = \"Conv4\"), \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2,2), name = \"Pool4\"),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation = 'relu', name = \"Dense5\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid', name = \"Output6\")\n",
        "])\n",
        "\n",
        "# Define the optimizer and loss function for the model\n",
        "cd_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005),\n",
        "                 loss = 'binary_crossentropy',\n",
        "                 metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUrDYatmgNqD",
        "colab_type": "text"
      },
      "source": [
        "###Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtorE_wJi94M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Fit the model and store the intermediate outputs\n",
        "history = cd_model.fit(train_generator,\n",
        "                            epochs = 30,\n",
        "                            steps_per_epoch = 450,\n",
        "                            validation_data = validation_generator,\n",
        "                            validation_steps =50,\n",
        "                            verbose = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSK6C8hBga17",
        "colab_type": "text"
      },
      "source": [
        "###Plot the loss and accuracy of the model w.r.t the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ac1NzijOtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Retrieve a list of results on training and test datasets for each training epoch\n",
        "acc      = history.history['accuracy']\n",
        "val_acc  = history.history['val_accuracy']\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get the total number of epochs\n",
        "epochs   = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot  (epochs, acc)\n",
        "plt.plot  (epochs, val_acc)\n",
        "plt.title ('Training and validation accuracy', color = \"white\")\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot  (epochs, loss)\n",
        "plt.plot  (epochs, val_loss)\n",
        "plt.title ('Training and validation loss', color = \"white\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omk2XL75iRGX",
        "colab_type": "text"
      },
      "source": [
        "###Get a summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cojRNOFh1aEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cd_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}